y ="Overwintering Success") +
scale_fill_manual(values = c("alive" = "gold",
"dead" = "grey")) +
theme_light() -> yard_overwinter
yard_overwinter
knitr::opts_chunk$set(echo = TRUE,
fig.align = "center")
# Load the tidyverse, class, caret, rpart, and rpart.plot packages
pacman::p_load(tidyverse, class, caret, rpart, rpart.plot, scales)
# Read in the "nba stats.csv" file and save it as nba
nba_stats <- read.csv("nba stats.csv") %>%
column_to_rownames(var = "player")
nba_stats
ggplot(data = nba_stats,
mapping = aes(x = position)) +
geom_bar(aes(y = (..count..)/sum(..count..),
fill = "blue3",
color = "black")) +
scale_y_continuous(labels = scales::percent,
expand = c(0, 0, 0.05, 0)) ->
gg_nba
ggplot(data = nba_stats,
mapping = aes(x = position)) +
geom_bar(aes(y = (..count..)/sum(..count..),
fill = "blue3",
color = "black")) +
scale_y_continuous(labels = scales::percent,
expand = c(0, 0, 0.05, 0)) ->
gg_nba
#most common position is SG
gg_nba
geom_bar(aes(y = (..count..)/sum(..count..)) +
ggplot(data = nba_stats,
mapping = aes(x = position)) +
geom_bar(aes(y = (..count..)/sum(..count..)) +
scale_y_continuous(labels = scales::percent,
expand = c(0, 0, 0.05, 0)) ->
gg_nba
gg_nba
ggplot(data = nba_stats,
ggplot(data = nba_stats,
mapping = aes(x = position)) +
geom_bar(aes(y = (..count..)/sum(..count..))) +
scale_y_continuous(labels = scales::percent,
expand = c(0, 0, 0.05, 0)) ->
gg_nba
ggplot(data = nba_stats,
ggplot(data = nba_stats,
mapping = aes(x = position)) +
geom_bar(aes(y = (..count..)/sum(..count..))) +
scale_y_continuous(labels = scales::percent) ->
gg_nba
ggplot(data = nba_stats,
mapping = aes(x = position)) +
geom_bar(aes(y = (..count..)/sum(..count..))) +
scale_y_continuous(labels = scales::percent) ->
gg_nba
#most common position is SG
gg_nba
ggplot(data = nba_stats,
mapping = aes(x = position)) +
geom_bar(aes(y = (..count..)/sum(..count..))) +
scale_y_continuous(labels = scales::percent,
expand = c(0, 0, 0.05, 0)) +
lab(x = "Position",
y = "Percentage")->
gg_nba
ggplot(data = nba_stats,
mapping = aes(x = position)) +
geom_bar(aes(y = (..count..)/sum(..count..))) +
scale_y_continuous(labels = scales::percent,
expand = c(0, 0, 0.05, 0)) +
labs(x = "Position",
y = "Percentage")->
gg_nba
gg_nba
#most common position is SG
ggplot(data = nba_stats,
mapping = aes(x = position)) +
geom_bar(aes(y = (..count..)/sum(..count..))) +
scale_y_continuous(labels = scales::percent) +
labs(x = "Position",
y = "Percentage")->
gg_nba
gg_nba
#most common position is SG
# create standardize function
#need to rescale the data so its normailzed (0-1)
# Function to standardize the data:
standardize <-
function(x){
return((x - mean(x))/sd(x))
}
# standardize the nba data
nba_stan <-
nba_stats |>
mutate(across(.cols = where(is.numeric),
.fns = standardize))
# confirm that standardization worked
nba_stan |>
summarize(across(.cols = where(is.numeric),
.fns = list(avg = mean,
sd = sd))) |>
round(digits = 5)
#the data were successfully standardized bacause they appear as 1s and 0s
# Keep this at the top of the codechunk
RNGversion("4.1.0")
set.seed(2870)
table(
predicted = knn(train = nba_norm[ , c("efficiency", "true_shot", "par3", "off_reb", "def_reb", "total_reb", "assist", "steal", "block", "usage")],
test = nba_norm[ , c("efficiency", "true_shot", "par3", "off_reb", "def_reb", "total_reb", "assist", "steal", "block", "usage")],
cl = nba_stats$position,
k = 7),
actual = nba_stats$position
) ->
nba_knn
# create normalization function
normalize <- function(x) {
norm_x <- (x-min(x))/(max(x)-min(x))
return(norm_x)
}
# normalize the nba data using the across() function to not specify each variable one at a time
nba_norm <-
nba_stats |>
mutate(across(.cols = where(is.numeric),
.fns = normalize))
# confirm that normalization worked
fivenum(nba_norm$efficiency)
# Keep this at the top of the codechunk
RNGversion("4.1.0")
set.seed(2870)
table(
predicted = knn(train = nba_norm[ , c("efficiency", "true_shot", "par3", "off_reb", "def_reb", "total_reb", "assist", "steal", "block", "usage")],
test = nba_norm[ , c("efficiency", "true_shot", "par3", "off_reb", "def_reb", "total_reb", "assist", "steal", "block", "usage")],
cl = nba_stats$position,
k = 7),
actual = nba_stats$position
) ->
nba_knn
knn_acc <-
tibble(k = 1:50,
knn_stan = -1,
knn_norm = -1)
knn_acc
for (i in 1:nrow(knn_acc)){
knn_stan <- knn.cv(train = nba_stan %>% dplyr::select(where(is.numeric)),
cl = nba_stan$position,
k = knn_acc[i, "k"])
knn_norm <- knn.cv(train = nba_norm %>%  dplyr::select(where(is.numeric)),
cl = nba_stan$position,
k = knn_acc$k[i])
knn_acc[i, "stan_acc"] <- mean(knn_stan == nba_stan$position) # mean() for handling logicals
knn_acc[i, "norm_acc"] <- mean(knn_norm == nba_norm$position)
}
knn_acc %>%
pivot_longer(cols = norm_acc:stan_acc,
names_to = "rescale",
values_to = "accuracy") ->
knn_long
knn_long
ggplot(data = knn_long,
mapping = aes(x = k,
y = accuracy,
color = rescale)) +
geom_line(linewidth = 2)
# Leave this at the top
RNGversion("4.1.0")
set.seed(187)
# Create the full classification tree below
nba_tree_full <-
rpart(formula = position ~ .,
data = nba_stats,
method = "class",
parms = list(split = "information"),
minsplit = 0,
minbucket = 0,
cp = -1)
# Display the cp table of the full tree:
nba_tree_full$cptable
nba_tree_full$cptable |>
data.frame() |>
slice_min(xerror) |>
mutate(xcutoff = xerror + xstd) |>
slice(1) |>
select(xcutoff) |>
as.numeric() ->
xcutoff
nba_tree_full$cptable |>
data.frame() |>
filter(xerror < xcutoff) |>
slice(1) |>
pull(CP)->
cp_prune
c("xerror" = xcutoff, "cp" = cp_prune)
nba_tree_pruned <-
prune(tree = nba_full,
cp = cp_prune)
nba_tree_pruned <-
prune(tree = nba_tree_full,
cp = cp_prune)
rpart.plot(x = nba_pruned,
type = 5,
extra = 101)
nba_tree_pruned <-
prune(tree = nba_tree_full,
cp = cp_prune)
rpart.plot(x = nba_tree_pruned,
type = 5,
extra = 101)
tree_matrix <-
confusionMatrix(data = predict(object = nba_tree_pruned,
tree_matrix
type = "class"),
tree_matrix <-
confusionMatrix(data = predict(object = nba_tree_pruned,
type = "class"),
reference = factor(nba$position),
positive = "yes",
dnn = c("predicted", "actual"))
tree_matrix <-
confusionMatrix(data = predict(object = nba_tree_pruned,
type = "class"),
reference = factor(nba_stats$position),
positive = "yes",
dnn = c("predicted", "actual"))
tree_matrix
caret::varImp(nba_tree_pruned) |>
arrange(desc(Overall))
# keep the players that were predicted incorrectly from our previous tree
nba |>
filter(position != predict(object = nba_tree_pruned,
type = "class")) ->
nba_wrong
# keep the players that were predicted incorrectly from our previous tree
nba_stats |>
filter(position != predict(object = nba_tree_pruned,
type = "class")) ->
nba_wrong
# Form the full tree on the incorrectly predicted players
tree_wrong <-
rpart(formula = position ~ .,
data = nba_wrong,
method = "class",
parms = list(split = "information"),
minsplit = 0,
minbucket = 0,
cp = -1
)
tree_wrong$cptable |>
data.frame() |>
slice_min(xerror) |>
mutate(xcutoff = xerror + xstd) |>
slice(1) |>
select(xcutoff) |>
as.numeric() ->
xcutoff
tree_wrong$cptable |>
data.frame() |>
filter(xerror < xcutoff) |>
slice(1) |>
pull(CP)->
cp_prune
c("xerror" = xcutoff, "cp" = cp_prune)
nba_wrong_pruned <-
prune(tree = tree_wrong,
cp = cp_prune)
rpart.plot(x = nba_wrong_pruned,
type = 5,
extra = 101)
tree_wrong_matrix <-
confusionMatrix(data = predict(object = nba_wrong_pruned,
tree_wrong_matrix
confusionMatrix(data = predict(object = nba_wrong_prune),
tree_wrong_matrix <-
confusionMatrix(data = predict(object = nba_wrong_prune),
tree_wrong_matrix
tree_wrong_matrix <-
confusionMatrix(data = predict(object = nba_wrong_prune,
type = "class"),
reference = factor(nba_wrong$position),
positive = "yes",
dnn = c("predicted", "actual")),
tree_wrong_matrix <-
confusionMatrix(data = predict(object = nba_wrong_prune,
type = "class"),
reference = factor(nba_wrong$position),
positive = "yes",
dnn = c("predicted", "actual"))
tree_wrong_matrix <-
confusionMatrix(data = predict(object = nba_wrong_pruned,
type = "class"),
reference = factor(nba_wrong$position),
positive = "yes",
dnn = c("predicted", "actual"))
tree_wrong_matrix
# set directory:
setwd("~/Documents/GitHub/SARE")
# install libraries
library(dplyr)
library(ggplot2)
library(lme4)
library(tidyr)
library(viridis)
library(car)
library(imputeTS)
# load in data
#ds <- read.csv("SARE_Field_database2022.csv", header = TRUE, stringsAsFactors = FALSE)
ds <- read.csv("SARE_field_database2022.csv", header = TRUE, stringsAsFactors = FALSE)
virus <- read.csv("DWV_SARE2021.csv", header = TRUE, stringsAsFactors = FALSE)
virus2022 <- read.csv("DWV_SARE2022.csv", header = TRUE, stringsAsFactors = FALSE)
virus2023 <- read.csv("Virus results 2024.csv", header = TRUE, stringsAsFactors = FALSE)
ds2023 <- read.csv("SARE field database2023.csv", header = TRUE, stringsAsFactors = FALSE)
# colonies that were removed
d <- ds[grepl(ds$comments, pattern = "removed from", fixed = TRUE),]
# make sure ids are unique
unique_to_remove <- unique(d$lab_ID)
# pull rows out that match these values
ds = filter(ds, !(lab_ID %in% unique_to_remove))
# this is where we split by year
ds_2021<- ds[ds$year == 2021, ]
ds_2022 <- ds[ds$year == 2022, ]
# for 2022 create a column that denotes whether a colony was treated for varroa mites
# check sampling event number for future analyses
ds_2022$varroaTreated <- ifelse(ds_2022$sampling_event == 9 & ds_2022$varroa_load_mites.100.bees >= 2, "treated", "not_treated")
# removing colonies that were treated
ds_2022 <- ds_2022[ds_2022$varroaTreated == "not_treated",]
# merge in 2022 virus data and make log trans and prevalence data
ds_2022 <- merge(x = ds_2022,y = virus2022, all.x = TRUE)
ds_2022$NormGenomeCopy <- ifelse(is.na(ds_2022$NormGenomeCopy), 0, ds_2022$NormGenomeCopy)
ds_2022$virusPrev <- ifelse(ds_2022$NormGenomeCopy > 0, 1, 0) # making all negative IDs into 0s Chekc if there should be some NAs
ds_2022$logDWV <- log10(ds_2022$NormGenomeCopy + 1)
ds_2022$uboPrev <- ifelse(ds_2022$UBO_assay_score >= 0.6, 1, 0)
# remove NAs from uba data set and make character variable
ds_2022UBO <- ds_2022[!is.na(ds_2022$uboPrev),]
ds_2022UBO$uboChar <- ifelse(ds_2022UBO$uboPrev==0, "UBO Neg.", "UBO pos.")
no0 <- ds_2022UBO[ds_2022UBO$virusPrev == 1, ] # only positive virus bees
# ubo by virus load
ggplot(no0, aes(x=yard, y=NormGenomeCopy, color=uboChar)) +
geom_boxplot(size=1) +
ylab("DWV (genome copies/bee)") + # y axis label
xlab("Bee Yard") + # x axis label
labs(color=NULL ) +
theme_minimal(base_size = 17) + # size of the text and label ticks
theme(legend.position = "top") + # place the legend at the top
scale_color_manual(values = c("blue", "slategrey")) +
scale_y_continuous(trans='log10')
vl <- lm(data = no0, logDWV ~ uboPrev * yard)
Anova(vl)
# summary of prevalence for virus by ubo and yard
prevSum <- ds_2022UBO %>% # operate on the dataframe (ds) and assign to new object (V)
group_by(uboChar, yard) %>% # pick variables to group by
summarise(
mean = mean(virusPrev, na.rm=T), # mean
N = length(virusPrev), # sample size
)
# ub0 by virus prev
ggplot(prevSum, aes(x=yard, y=mean, fill=uboChar)) +
geom_bar(stat = "identity", position = "dodge") +
ylab("DWV Prevalence") + # y axis label
xlab("Bee Yard") + # x axis label
labs(fill=NULL ) +
theme_minimal(base_size = 17) + # size of the text and label ticks
theme(legend.position = "top") + # place the legend at the top
scale_fill_manual(values = c("blue", "slategrey"))
vp <- glm(data = ds_2022UBO, virusPrev ~ uboPrev * yard, family = binomial(link="logit"))
Anova(vp)
# summary of prevalence for virus by ubo and yard
prevSum <- ds_2022UBO %>% # operate on the dataframe (ds) and assign to new object (V)
group_by(uboChar, yard) %>% # pick variables to group by
summarise(
mean = mean(virusPrev, na.rm=T), # mean
N = length(virusPrev), # sample size
)
# ub0 by virus prev
ggplot(prevSum, aes(x=yard, y=mean, fill=uboChar)) +
geom_bar(stat = "identity", position = "dodge") +
ylab("DWV Prevalence") + # y axis label
xlab("Bee Yard") + # x axis label
labs(fill=NULL ) +
theme_minimal(base_size = 17) + # size of the text and label ticks
theme(legend.position = "top") + # place the legend at the top
scale_fill_manual(values = c("blue", "slategrey"))
vp <- glm(data = ds_2022UBO, virusPrev ~ uboPrev * yard, family = binomial(link="logit"))
Anova(vp)
ds_2023_only <- filter(ds2023, year == 2023)
full_ds2023 <- merge(virus2023, ds_2023_only, by = c('lab_ID', 'yard'))
full_ds2023 %>%
pivot_longer(
cols = Copies.uL.DWV.A,
Copies.uL.DWV.B,
Copies.uL.BQCV,
Copies.uL.IAPV,
Copies.uL.SBV,
Copies.uL.CBPV,
Copies.uL.LSV,
names_to = "virus",
values_to = "virus_count"
)
View(full_ds2023)
ds2023 <- read.csv("SARE field database2023.csv", header = TRUE, stringsAsFactors = FALSE)
ds_2023_only <- filter(ds2023, year == 2023)
full_ds2023 <- merge(virus2023, ds_2023_only, by = c('lab_ID', 'yard'))
full_ds2023 %>%
pivot_longer(
cols = Copies.uL.DWV.A,
Copies.uL.DWV.B,
Copies.uL.BQCV,
Copies.uL.IAPV,
Copies.uL.SBV,
Copies.uL.CBPV,
Copies.uL.LSV,
names_to = "virus",
values_to = "virus_count"
)
full_ds2023$uboPrev <- ifelse(full_ds2023$UBO_assay_score >= 0.6, 1, 0)
View(full_ds2023)
full_ds2023 %>%
select(lab_ID, yard, treatment_group, uboPrev, Copies.uL.DWV.A, Copies.uL.DWV.B, Copies.uL.BQCV, Copies.uL.CBPV, Copies.uL.IAPV, Copies.uL.SBV, Copies.uL.LSV)
full_ds2023_sel <- full_ds2023 %>%
select(lab_ID, yard, treatment_group, uboPrev, Copies.uL.DWV.A, Copies.uL.DWV.B, Copies.uL.BQCV, Copies.uL.CBPV, Copies.uL.IAPV, Copies.uL.SBV, Copies.uL.LSV)
View(full_ds2023_sel)
full_ds2023_sel %>%
pivot_longer(
cols = Copies.uL.DWV.A:Copies.uL.LSV,
names_to = "virus",
values_to = "virus_count"
)
full_ds2023_sel <- full_ds2023 %>%
select(lab_ID, yard, treatment_group, uboPrev, Copies.uL.DWV.A, Copies.uL.DWV.B, Copies.uL.BQCV, Copies.uL.CBPV, Copies.uL.IAPV, Copies.uL.SBV, Copies.uL.LSV)
full_ds2023_sel <- full_ds2023 %>%
select(lab_ID, yard, treatment_group, uboPrev, Copies.uL.DWV.A, Copies.uL.DWV.B, Copies.uL.BQCV, Copies.uL.CBPV, Copies.uL.IAPV, Copies.uL.SBV, Copies.uL.LSV) %>%
pivot_longer(
cols = Copies.uL.DWV.A:Copies.uL.LSV,
names_to = "virus",
values_to = "virus_count"
)
View(full_ds2023_sel)
full_ds2023_sel %>%
group_by(treatment_group) %>%
summarise(
meanDWVa = mean(Copies.uL.DWV.A, na.rm=T),
meanDWVb = mean(Copies.uL.DWV.A, na.rm=T)
)
full_ds2023_sel %>%
group_by(treatment_group)
full_ds2023_sel <- full_ds2023 %>%
select(lab_ID, yard, treatment_group, uboPrev, Copies.uL.DWV.A, Copies.uL.DWV.B, Copies.uL.BQCV, Copies.uL.CBPV, Copies.uL.IAPV, Copies.uL.SBV, Copies.uL.LSV)
full_ds2023_selV <- full_ds2023_sel %>%
pivot_longer(
cols = Copies.uL.DWV.A:Copies.uL.LSV,
names_to = "virus",
values_to = "virus_count"
)
full_ds2023_sel %>%
group_by(treatment_group) %>%
summarise(meanDWVa = mean(Copies.uL.DWV.A))
full_ds2023_sel %>%
group_by(treatment_group) %>%
summarise(meanDWVa = mean(Copies.uL.DWV.A),
meanDWVb = mean(Copies.uL.DWV.B),
meanLSV = mean(Copies.uL.LSV),
meanCBPV = mean(Copies.uL.CBPV),
meanBQCV = mean(Copies.uL.BQCV),
meanIAPV = mean(Copies.uL.IAPV),
meanSBV = mean(Copies.uL.SBV))
full_ds2023_sel_sum <-  full_ds2023_sel %>%
group_by(treatment_group) %>%
summarise(meanDWVa = mean(Copies.uL.DWV.A),
meanDWVb = mean(Copies.uL.DWV.B),
meanLSV = mean(Copies.uL.LSV),
meanCBPV = mean(Copies.uL.CBPV),
meanBQCV = mean(Copies.uL.BQCV),
meanIAPV = mean(Copies.uL.IAPV),
meanSBV = mean(Copies.uL.SBV))
barplot(as.matrix(full_ds2023_sel_sum))
barplot(full_ds2023_sel_sum)
full_ds2023_sel_sum <-  full_ds2023_sel %>%
group_by(treatment_group) %>%
summarise(meanDWVa = mean(Copies.uL.DWV.A),
meanDWVb = mean(Copies.uL.DWV.B),
meanLSV = mean(Copies.uL.LSV),
meanCBPV = mean(Copies.uL.CBPV),
meanBQCV = mean(Copies.uL.BQCV),
meanIAPV = mean(Copies.uL.IAPV),
meanSBV = mean(Copies.uL.SBV))
View(full_ds2023_sel_sum)
dat <- tibble(
patientID = c("a", "b", "c"),
tot_cells = c(2773, 3348, 4023),
tot_cells_zone1 = c(994, 1075, 1446),
tot_cells_zone2 = c(1141, 1254, 1349),
tot_cells_zone3 = c(961, 1075, 1426)
)
View(dat)
to_plot <- pivot_longer(full_ds2023_sel_sum, cols = starts_with("Copies"), names_to = "Virus", values_to = "Count")
to_plot <- pivot_longer(full_ds2023_sel_sum, cols = starts_with("Copies."), names_to = "Virus", values_to = "Count")
to_plot <- pivot_longer(full_ds2023_sel_sum, cols = starts_with("Cop"), names_to = "Virus", values_to = "Count")
to_plot <- pivot_longer(full_ds2023_sel_sum, cols = starts_with("mean"), names_to = "Virus", values_to = "Count")
View(to_plot)
ggplot(to_plot, aes(x = Virus, y = Count, fill = treatment_group)) +
geom_bar(position="dodge", stat="identity")
ggplot(to_plot, aes(x = Virus, y = Count, fill = treatment_group)) +
geom_bar(position="dodge", stat="identity") +
y_lim(c(0,2e+08))
ggplot(to_plot, aes(x = Virus, y = Count, fill = treatment_group)) +
geom_bar(position="dodge", stat="identity") +
y_lim(c(0,2e+08))
ggplot(to_plot, aes(x = Virus, y = Count, fill = treatment_group)) +
geom_bar(position="dodge", stat="identity") +
ylim(c(0,2e+08))
ggplot(to_plot, aes(x = Virus, y = Count, fill = treatment_group)) +
geom_bar(position="dodge", stat="identity")
