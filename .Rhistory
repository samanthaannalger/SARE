import platform
import platform
# make sure python 3.9 is loaded
print(platform.python_version())
from spacetime.input.readData import read_data
from spacetime.scale.rasterAlign import raster_align
from spacetime.scale.rasterTrim import raster_trim
from spacetime.objects.fileObject import file_object
from spacetime.operations.cubeSmasher import cube_smasher
from spacetime.operations.cubeSmasher import cube_smasher
from spacetime.operations.makeCube import make_cube
from spacetime.operations.loadCube import load_cube
from spacetime.graphics.dataPlot import plot_cube
from spacetime.graphics.dataPlot import plot_cube
from spacetime.operations.time import cube_time, return_time, scale_time, select_time
from spacetime.operations.cubeToDataframe import cube_to_dataframe
library(tidyverse)
library(stringr)
library(raster)
months <- c(paste0("0",seq(1,9)),10,11,12)
years <- seq(1981,1995)
precip <- c(paste0("https://os.zhdk.cloud.switch.ch/envicloud/chelsa/chelsa_V2/GLOBAL/monthly/pr/CHELSA_pr_",
rep(months,30),"_",rep(years,each = 12),"_V.2.1.tif"))
tmin <- c(paste0("https://os.zhdk.cloud.switch.ch/envicloud/chelsa/chelsa_V2/GLOBAL/monthly/tasmin/CHELSA_tasmin_",
rep(months,15),"_",rep(years,each = 12),"_V.2.1.tif"))
tmax <- c(paste0("https://os.zhdk.cloud.switch.ch/envicloud/chelsa/chelsa_V2/GLOBAL/monthly/tasmax/CHELSA_tasmax_",
rep(months,15),"_",rep(years,each = 12),"_V.2.1.tif"))
txt_file <- c(precip, tmin, tmax)
txt_file
# raster I use to define cropping extent
ref_extent <- raster("D:/Climate/CHELSA2/bio1_1981-2010_V.2.1.tif")
# raster I use to define cropping extent
ref_extent <- raster("/Users/pburnham/Documents/geospatialData/Carya_ovata/Carya_ovata_sim_disc_10km.tif")
# raster I use to define cropping extent
ref_extent <- raster("/Users/pburnham/Documents/geospatialData/Carya_ovata/Carya_ovata_sim_disc_10km.tif")
plot(ref_extent)
for(f in c(1:length(txt_file))){
# Download file from CHELSA
url <- txt_file[f]
name <- gsub(".*/CHELSA_","",url)
dest_file <- paste("D:/Climate/CHELSA_BIOCLIM+/",name,sep ="")
download.file(url=url, destfile=dest_file, method="auto", quiet = F, mode = "wb", cacheOK = TRUE)
# Crop and save cropped file
org_file <- raster(dest_file)
e <- extent(ref_extent)
cropped_file <- crop(org_file,e)
writeRaster(cropped_file, filename=dest_file, overwrite=TRUE)
print(name)
}
z
for(f in c(1:length(txt_file))){
# Download file from CHELSA
url <- txt_file[f]
name <- gsub(".*/CHELSA_","",url)
print(name)
dest_file <- paste("D:/Climate/CHELSA_BIOCLIM+/",name,sep ="")
download.file(url=url, destfile=dest_file, method="auto", quiet = F, mode = "wb", cacheOK = TRUE)
# Crop and save cropped file
org_file <- raster(dest_file)
e <- extent(ref_extent)
cropped_file <- crop(org_file,e)
writeRaster(cropped_file, filename=dest_file, overwrite=TRUE)
print(name)
}
for(f in c(1:length(txt_file))){
# Download file from CHELSA
url <- txt_file[f]
name <- gsub(".*/CHELSA_","",url)
dest_file <- paste("/Users/pburnham/Documents/geospatialData/chelsa_data/",name,sep ="")
download.file(url=url, destfile=dest_file, method="auto", quiet = F, mode = "wb", cacheOK = TRUE)
# Crop and save cropped file
org_file <- raster(dest_file)
e <- extent(ref_extent)
cropped_file <- crop(org_file,e)
writeRaster(cropped_file, filename=dest_file, overwrite=TRUE)
}
for(f in c(1:length(txt_file))){
print(f)
# Download file from CHELSA
url <- txt_file[f]
name <- gsub(".*/CHELSA_","",url)
dest_file <- paste("/Users/pburnham/Documents/geospatialData/chelsa_data/",name,sep ="")
download.file(url=url, destfile=dest_file, method="auto", quiet = F, mode = "wb", cacheOK = TRUE)
# Crop and save cropped file
org_file <- raster(dest_file)
e <- extent(ref_extent)
cropped_file <- crop(org_file,e)
writeRaster(cropped_file, filename=dest_file, overwrite=TRUE)
print(name)
}
getOption('timeout')
options(timeout=100)
getOption('timeout')
for(f in c(1:length(txt_file))){
print(f)
# Download file from CHELSA
url <- txt_file[f]
name <- gsub(".*/CHELSA_","",url)
dest_file <- paste("/Users/pburnham/Documents/geospatialData/chelsa_data/",name,sep ="")
download.file(url=url, destfile=dest_file, method="auto", quiet = F, mode = "wb", cacheOK = TRUE)
# Crop and save cropped file
org_file <- raster(dest_file)
e <- extent(ref_extent)
cropped_file <- crop(org_file,e)
writeRaster(cropped_file, filename=dest_file, overwrite=TRUE)
print(name)
}
options(timeout=100)
txt_file
# set directory:
setwd("~/Documents/GitHub/SARE")
# install libraries
library(dplyr)
library(ggplot2)
library(lme4)
library(tidyr)
library(viridis)
library(car)
library(imputeTS)
# load in data
#ds <- read.csv("SARE_Field_database2022.csv", header = TRUE, stringsAsFactors = FALSE)
ds <- read.csv("SARE_field_database2022.csv", header = TRUE, stringsAsFactors = FALSE)
virus <- read.csv("DWV_SARE2021.csv", header = TRUE, stringsAsFactors = FALSE)
# colonies that were removed
d <- ds[grepl(ds$comments, pattern = "removed from", fixed = TRUE),]
# make sure ids are unique
unique_to_remove <- unique(d$lab_ID)
# pull rows out that match these values
ds = filter(ds, !(lab_ID %in% unique_to_remove))
# this is where we split by year
ds_2021<- ds[ds$year == 2021, ]
ds_2022 <- ds[ds$year == 2022, ]
View(ds_2022)
# take only usefull columns
ds_2022_clean <- select(ds_2022, yard, treatment_grp, lab_ID, sampling_event, overwintering_success, frame_of_bees_FHA, FKB_percentile, UBO_assay_score, varroa_load_mites.100.bees, nosema_load_spores.bee)
# take only usefull columns
ds_2022_clean <- select(ds_2022, yard, treatment_grp, lab_ID, sampling_event, overwinter_success, frame_of_bees_FHA, FKB_percentile, UBO_assay_score, varroa_load_mites.100.bees, nosema_load_spores.bee)
# remove na rows
ds_2022_clean[rowSums(is.na(ds_2022_clean)) != ncol(ds_2022_clean), ]
# remove na rows
ds_2022_clean[rowSums(is.na(ds_2022_clean)) == ncol(ds_2022_clean), ]
# remove na rows
ds_2022_clean <- ds_2022_clean[rowSums(is.na(ds_2022_clean)) != ncol(ds_2022_clean), ]
View(ds_2022_clean)
summary_2022 <- ds_2022_clean %>%
group_by(yard, lab_ID, treatment_grp) %>%
summarise(
mean = mean(varroa_load_mites.100.bees, na.rm=T),
)
summary_2022
View(summary_2022)
View(ds_2022_clean)
mean(c(NA, NA, NA), na.rm=T)
mean(c(NA, 0, NA), na.rm=T)
summary_2022 <- ds_2022_clean %>%
group_by(yard, lab_ID, overwinter_success) %>%
summarise(
mean = mean(varroa_load_mites.100.bees, na.rm=T),
)
summary_2022
summary_2022 <- ds_2022_clean %>%
group_by(yard, lab_ID) %>%
summarise(
mean = mean(varroa_load_mites.100.bees, na.rm=T),
)
table(summary_2022$lab_ID)
summary_2022 <- ds_2022_clean %>%
group_by(yard, lab_ID, overwinter_success) %>%
summarise(
mean = mean(varroa_load_mites.100.bees, na.rm=T),
)
table(summary_2022$lab_ID)
grepl("dead", summary_2022$overwinter_success)
summary_2022[grepl("dead", summary_2022$overwinter_success),]
summary_2022[!grepl("dead", summary_2022$overwinter_success),]
summary_2022_clean <- summary_2022[!grepl("dead", summary_2022$overwinter_success),]
# remove column: overwinter success
summary_2022_clean$overwinter_success =  NULL
summary_2022_clean
# summarize data set into one time point
summary_2022 <- ds_2022_clean %>%
group_by(yard, lab_ID, overwinter_success) %>%
summarise(
varroa = max(varroa_load_mites.100.bees, na.rm=T),
nosema = max(nosema_load_spores.bee, na.rm=T),
)
# remove dead and missing colonies
summary_2022_clean <- summary_2022[!grepl("dead", summary_2022$overwinter_success),]
# remove column: overwinter success
summary_2022_clean$overwinter_success =  NULL
View(summary_2022_clean)
View(ds_2022_clean)
# fk and ubo binary variables created here
ds_2022_clean2$FK_binary <- ifelse(ds_2022_clean$FKB_percentile >= 0.95, 1, 0)
# fk and ubo binary variables created here
ds_2022_clean$FK_binary <- ifelse(ds_2022_clean$FKB_percentile >= 0.95, 1, 0)
ds_2022_clean$UBO_binary <- ifelse(ds_2022_clean$UBO_assay_score >= 0.65, 1, 0)
# summarize data set into one time point
summary_2022 <- ds_2022_clean %>%
group_by(yard, lab_ID, overwinter_success) %>%
summarise(
varroa = max(varroa_load_mites.100.bees, na.rm=T),
nosema = max(nosema_load_spores.bee, na.rm=T),
FKA = sum(FK_binary, na.rm=T),
UBO = sum(UBO_binary, na.rm=T),
)
# remove dead and missing colonies
summary_2022_clean <- summary_2022[!grepl("dead", summary_2022$overwinter_success),]
# remove column: overwinter success
summary_2022_clean$overwinter_success =  NULL
chisq.test(summary_2022_clean$FKA, summary_2022_clean$UBO)
chisq.test(summary_2022_clean$FKA~summary_2022_clean$UBO)
fisher.test(summary_2022_clean$FKA, summary_2022_clean$UBO)
# summarize data set into one time point
summary_2022 <- ds_2022_clean %>%
group_by(yard, lab_ID, overwinter_success) %>%
summarise(
varroa = max(varroa_load_mites.100.bees, na.rm=T),
nosema = max(nosema_load_spores.bee, na.rm=T),
FKA = sum(FK_binary, na.rm=T),
UBO = sum(UBO_binary, na.rm=T),
FOB = mean(frame_of_bees_FHA, na.rm=T)
)
# remove dead and missing colonies
summary_2022_clean <- summary_2022[!grepl("dead", summary_2022$overwinter_success),]
# remove column: overwinter success
summary_2022_clean$overwinter_success =  NULL
# summarize data set into one time point
summary_2022 <- ds_2022_clean %>%
group_by(yard, lab_ID, overwinter_success) %>%
summarise(
varroa = max(varroa_load_mites.100.bees, na.rm=T),
nosema = max(nosema_load_spores.bee, na.rm=T),
FKA = sum(FK_binary, na.rm=T),
UBO = sum(UBO_binary, na.rm=T),
FOB = max(frame_of_bees_FHA, na.rm=T)
)
# remove dead and missing colonies
summary_2022_clean <- summary_2022[!grepl("dead", summary_2022$overwinter_success),]
# remove column: overwinter success
summary_2022_clean$overwinter_success =  NULL
summary_2022_clean$lab_ID == 56
summary_2022_clean[summary_2022_clean$lab_ID == 56,]
summary_2022_clean[summary_2022_clean$lab_ID == 56,]$FOB <- 8
summary_2022_clean[summary_2022_clean$lab_ID == 56,]$FOB <- "8"
summary_2022_clean
summary_2022_clean$FOB <- as.numeric(summary_2022_clean$FOB)
summary_2022_clean
